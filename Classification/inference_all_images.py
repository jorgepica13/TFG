# -*- coding: utf-8 -*-
"""inference_all_images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1620pbnbJqa7rDrlZWRUzlJ4Mv5BRKUVN
"""

# Commented out IPython magic to ensure Python compatibility.
import sys,os
# change directory
# %cd '/content/drive/My Drive'
# Let's import the python module exercises.py  to have access to its functions and Classes
path_to_module='/mnt/homeGPU/jpicado/TFG/classification/'
sys.path.append(os.path.abspath(path_to_module))
import class_utils, class_model, class_datasets

import torch
import cv2
import torchvision.transforms as transforms
# import argparse

# from torchvision.models import alexnet, AlexNet_Weights
# from torchvision.models import vgg19_bn, VGG19_BN_Weights
# from torchvision.models import densenet201, DenseNet201_Weights
# from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights
from torchvision.models import resnet50, ResNet50_Weights

# construct the argument parser
# parser = argparse.ArgumentParser()
# parser.add_argument('-i', '--input',
#     default='input/butterflies_rev2/test/adonis/1.jpg',
#     help='path to the input image')
# args = vars(parser.parse_args())

# the computation device
device = ('cuda' if torch.cuda.is_available() else 'cpu')

# list containing all the class labels
labels = ['elliptical', 'spiral', 'uncertain']

# initialize the model and load the trained weights

# model = model.CNNModel().to(device)

# weights = AlexNet_Weights.DEFAULT
# model = alexnet(weights).to(device)

# weights = VGG19_BN_Weights.DEFAULT
# model = vgg19_bn(weights).to(device)

# weights = DenseNet201_Weights.DEFAULT
# model = densenet201(weights).to(device)

# weights = EfficientNet_B7_Weights.DEFAULT
# model = efficientnet_b7(weights).to(device)

weights = ResNet50_Weights.DEFAULT
model = resnet50(weights).to(device)


checkpoint = torch.load('/mnt/homeGPU/jpicado/TFG/classification/outputs/model.pth', map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# define preprocess transforms
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.5, 0.5, 0.5],
        std=[0.5, 0.5, 0.5]
    )
])

# image_test = '/content/drive/My Drive/DATASET/test/spiral/Dr7_588016878822228302.jpg'
# from google.colab.patches import cv2_imshow

def success_rate(image_test):
  # read and preprocess the image
  image = cv2.imread(image_test)
  # get the ground truth class
  gt_class = image_test.split('/')[-2]
  orig_image = image.copy()
  # convert to RGB format
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  image = transform(image)
  # add batch dimension
  image = torch.unsqueeze(image, 0)
  with torch.no_grad():
      outputs = model(image.to(device))
  output_label = torch.topk(outputs, 1)

  if len(labels) <= int(output_label.indices):
    return -1

  pred_class = labels[int(output_label.indices)]
  cv2.putText(orig_image,
      f"GT: {gt_class}",
      (10, 25),
      cv2.FONT_HERSHEY_SIMPLEX,
      0.6, (0, 255, 0), 2, cv2.LINE_AA
  )
  cv2.putText(orig_image,
      f"Pred: {pred_class}",
      (10, 55),
      cv2.FONT_HERSHEY_SIMPLEX,
      0.6, (0, 0, 255), 2, cv2.LINE_AA
  )

  if({gt_class} == {pred_class}):
    return 1
  return 0

  # print(f"GT: {gt_class}, pred: {pred_class}")
  # cv2_imshow(orig_image)
  # cv2.waitKey(0)
  # cv2.imwrite(f"outputs/{gt_class}{image_test.split('/')[-1].split('.')[0]}.png",
  #     orig_image)

import os

ruta_dir = '/mnt/homeGPU/jpicado/TFG/dataset_restored/test'
contenido = os.listdir(ruta_dir)

total = 0
correct = 0
image_test = ''

for fichero in contenido:
  directory = os.path.join(ruta_dir, fichero)
  if os.path.isdir(directory):
    list_images = os.listdir(directory)

    for i in list_images:
      image_test = os.path.join(directory, i)
      if os.path.isfile(image_test) and i.endswith('.jpg'):
        if(success_rate(image_test) == 1):
          correct += 1
        
        total += 1


print("El numero de aciertos ha sido: " + str(correct))
print("El numero de imagenes testeadas ha sido: " + str(total))

percentage = correct/total * 100
print("El porcentaje de acierto de test es de: " + str(percentage) + "%.")